{
    "debug mode": 1,
    "// training parameters //": 0,
    "batch_size": 100,
    "epochs": 50,
    "batches per epoch": 400,
    "do curriculum learning": 0,
    "loss_function": "mean_squared_error",
    "epochs pointwise loss": 0,
    "val_fraction": 0.5,
    "learning rate": 0.001,
    "// Network parameters //": 0,
    "dropout ratio": 0.5,
    "dilation rate": 2,
    "optimizer": "adam",
    "number of base filters": 64,
    "number of encoder decoder blocks": 2,
    "convolution kernel size": 3,
    "do_attention": 1,
    "// VIT parameters //": 0,
    "patch_size": 16,
    "projection_dim": 256,
    "num_heads": 8,
    "transformer_layers": 8,
    "fully_connected_expand": 4,
    "// preprocess parameters //": 0,
    "rank wing size": 2,
    "model type": "MODEL_18_POINTS_PER_WING",
    "test_path": "-",
    "data_path": "C:\\Users\\amita\\PycharmProjects\\pythonProject\\vision\\train_nn_project\\train_pose_estimation\\training_datasets\\combined_dataset.h5",
    "mix_with_test": 0,
    "mask dilation": 1,
    "single time channel": 0,
    "// augmentations parameters //": 0,
    "custom": 0,
    "augmentation shift x y": 10,
    "rotation range": 30,
    "seed": 1,
    "horizontal flip": 0,
    "vertical flip": 0,
    "shear_range": 10,
    "// augmentations using keras ImageGenerator": 0,
    "zoom range": [
        0.8,
        1.2
    ],
    "interpolation order": 3,
    "// saving configurations //": 0,
    "base output path": "models",
    "clean": 0,
    "// callbacks parameters //": 0,
    "// ReduceLROnPlateau": 0,
    "reduce_lr_factor": 0.1,
    "reduce_lr_patience": 3,
    "reduce_lr_min_delta": 1e-05,
    "reduce_lr_cooldown": 0,
    "reduce_lr_min_lr": 1e-10,
    "save_every_epoch": 0
}